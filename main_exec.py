# -*- coding: utf-8 -*-
"""main_exec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nY-nxR7H-WBb3BPq9veOcLEofjS6Y8lw
"""

"""
COMPLETE MAIN EXECUTION SCRIPT FOR PARKINSON'S DISEASE CLASSIFICATION
Fixed version with dimension matching for encoder weights

Prerequisites:
1. All parquet files in the same directory (motor.parquet, cog.parquet, merged_df.parquet,
   df2_Selected.parquet, Merged_Df.parquet, sleep.parquet, dti.parquet, mri.parquet)
2. master_patient_split.pkl (run master_patient_split_(1).py first)
3. Trained encoder weights (motor_encoder_weights.pth, nonmotor_encoder_weights.pth,
   imaging_encoder_weights.pth)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import pickle
from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,
                            roc_auc_score, confusion_matrix, f1_score)
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import wilcoxon
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    print("Warning: SHAP not available. Install with: pip install shap")


# ============================================================================
# ENCODER ARCHITECTURES
# ============================================================================

class TransformerMotorEncoder(nn.Module):
    """Transformer-based Motor Encoder - 16-dim output"""
    def __init__(self, input_dim=14, latent_dim=16, num_heads=4, num_layers=2, dropout=0.4):
        super().__init__()
        self.embedding = nn.Sequential(
            nn.Linear(input_dim, latent_dim),
            nn.LayerNorm(latent_dim),
            nn.Dropout(dropout)
        )
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=latent_dim, nhead=num_heads, dim_feedforward=latent_dim*4,
            dropout=dropout, activation='gelu', batch_first=True, norm_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.output_norm = nn.LayerNorm(latent_dim)

    def forward(self, x):
        # x is expected to be (batch, input_dim). unsqueeze(1) makes it (batch, 1, input_dim) for transformer sequence of length 1
        x = self.embedding(x.unsqueeze(1))
        x = self.transformer(x)
        x = x.squeeze(1)
        return self.output_norm(x)


class CategoryEncoder(nn.Module):
    """LSTM encoder for non-motor categories (sequence data)"""
    def __init__(self, input_dim, embed_dim):
        super().__init__()
        hidden = embed_dim // 2
        # Input: (batch, seq_len, input_dim) -> Output: (batch, seq_len, hidden*2)
        self.lstm = nn.LSTM(input_dim, hidden, bidirectional=True, batch_first=True)
        # Assuming the final output is based on the sequence mean/last time step,
        # but the original code structure passes the sequence output (h) to mu/logvar
        # We'll use sequence output shape (batch, seq_len, embed_dim) where embed_dim = hidden*2
        self.mu = nn.Linear(embed_dim, embed_dim)
        self.logvar = nn.Linear(embed_dim, embed_dim)

    def reparam(self, mu, logvar):
        if self.training:
            std = torch.exp(0.5 * logvar)
            return mu + std * torch.randn_like(std)
        return mu

    def forward(self, x):
        # x: (batch, seq_len, input_dim)
        h, _ = self.lstm(x) # h: (batch, seq_len, embed_dim)
        mu, logvar = self.mu(h), self.logvar(h)
        return self.reparam(mu, logvar), mu, logvar


class NonMotorEncoder(nn.Module):
    """Non-Motor Encoder - 16-dim common output (fused via mean pooling)"""
    def __init__(self, input_dims, embed_dims, common_dim=16):
        super().__init__()
        self.encoders = nn.ModuleList([CategoryEncoder(dim, ed) for dim, ed in zip(input_dims, embed_dims)])
        # Project from each category's embed_dim to the common_dim (16)
        self.projectors = nn.ModuleList([nn.Linear(ed, common_dim) for ed in embed_dims])
        self.common_dim = common_dim

    def forward(self, x_list):
        zs, mus, logs = [], [], []
        for encoder, proj, x in zip(self.encoders, self.projectors, x_list):
            # x: (batch, seq_len, input_dim)
            z_seq, mu, logvar = encoder(x) # z_seq: (batch, seq_len, embed_dim)

            # Project each time step's embedding to common_dim
            z_proj_seq = proj(z_seq) # z_proj_seq: (batch, seq_len, common_dim)

            # Sequence pooling (mean over sequence length)
            z_pooled = z_proj_seq.mean(dim=1) # z_pooled: (batch, common_dim)

            zs.append(z_pooled)
            mus.append(mu)
            logs.append(logvar)

        # Fused is the mean of the pooled embeddings across the 5 non-motor categories
        # Stacked: (batch, common_dim, num_categories) -> Mean across categories: (batch, common_dim)
        fused = torch.stack(zs, dim=2).mean(dim=2)

        # Note: The original code had an extra .mean(dim=1) which is likely incorrect
        # if zs already holds pooled (batch, common_dim) features.
        # However, to maintain the original intent, we'll ensure 'pooled' is the intended single feature vector.
        # Since zs already contains pooled features (batch, common_dim), 'fused' is the final output.
        pooled = fused # final nonmotor embedding (batch, common_dim)

        return pooled, mus, logs


class ImagingEncoder(nn.Module):
    """Imaging Encoder - 16-dim output (VAE-like structure)"""
    def __init__(self, input_dim, latent_dim=16, hidden_dims=[256, 128], dropout_p=0.4):
        super().__init__()
        layers = []
        prev_dim = input_dim
        for h_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, h_dim))
            layers.append(nn.ReLU())
            layers.append(nn.BatchNorm1d(h_dim))
            layers.append(nn.Dropout(dropout_p))
            prev_dim = h_dim
        self.encoder = nn.Sequential(*layers)
        self.fc_mu = nn.Linear(prev_dim, latent_dim)
        self.fc_logvar = nn.Linear(prev_dim, latent_dim)
        self.latent_dim = latent_dim

    def reparameterize(self, mu, logvar):
        if self.training:
            std = torch.exp(0.5 * logvar)
            eps = torch.randn_like(std)
            return mu + eps * std
        return mu

    def forward(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        z = self.reparameterize(mu, logvar)
        return z, mu, logvar


class AttentionFusion(nn.Module):
    """Attention-based fusion - outputs 48-dim (16 x 3)"""
    def __init__(self, latent_dim=16, num_modalities=3, num_heads=4):
        super().__init__()
        self.latent_dim = latent_dim
        self.num_modalities = num_modalities
        # MultiheadAttention requires K, Q, V of shape (sequence_length, batch_size, embed_dim)
        # Since we have 3 "tokens" (modalities) per patient, sequence_length=3
        self.attention = nn.MultiheadAttention(
            embed_dim=latent_dim, num_heads=num_heads, batch_first=True, dropout=0.1
        )
        self.norm = nn.LayerNorm(latent_dim)
        self.fused_dim = latent_dim * num_modalities

    def forward(self, motor_emb, nonmotor_emb, imaging_emb):
        # motor/nonmotor/imaging_emb are (batch_size, latent_dim)
        # Stacked: (batch_size, num_modalities, latent_dim)
        stacked = torch.stack([motor_emb, nonmotor_emb, imaging_emb], dim=1)

        # Q, K, V are all the stacked embeddings
        # attended: (batch_size, num_modalities, latent_dim)
        attended, attn_weights = self.attention(stacked, stacked, stacked)

        attended = self.norm(attended)
        # Flatten to (batch_size, num_modalities * latent_dim) = (batch_size, 48)
        fused = attended.reshape(attended.size(0), -1)
        return fused, attn_weights


class UnifiedFusedEncoder(nn.Module):
    """Complete fused encoder with attention - 48-dim output"""
    def __init__(self, motor_encoder, nonmotor_encoder, imaging_encoder, latent_dim=16, freeze_encoders=True):
        super().__init__()
        self.motor_encoder = motor_encoder
        self.nonmotor_encoder = nonmotor_encoder
        self.imaging_encoder = imaging_encoder
        self.latent_dim = latent_dim

        if freeze_encoders:
            for param in self.motor_encoder.parameters():
                param.requires_grad = False
            for param in self.nonmotor_encoder.parameters():
                param.requires_grad = False
            for param in self.imaging_encoder.parameters():
                param.requires_grad = False

        self.fusion = AttentionFusion(latent_dim=latent_dim, num_modalities=3)
        self.fused_dim = 48

    def forward(self, motor_x, nonmotor_x_list, imaging_x):
        # Get embeddings: all are (batch_size, latent_dim)
        motor_emb = self.motor_encoder(motor_x)
        nonmotor_emb, mus, logs = self.nonmotor_encoder(nonmotor_x_list)
        imaging_emb, img_mu, img_logvar = self.imaging_encoder(imaging_x)

        # Fuse embeddings
        fused, attn_weights = self.fusion(motor_emb, nonmotor_emb, imaging_emb)

        individual_embeddings = {
            'motor': motor_emb,
            'nonmotor': nonmotor_emb,
            'imaging': imaging_emb,
            'attention_weights': attn_weights
        }
        return fused, individual_embeddings

    def get_embedding_dim(self):
        return self.fused_dim


class PDStageClassifier(nn.Module):
    """Three-stage Parkinson's Disease classifier"""
    def __init__(self, input_dim=48, hidden_dim=128, num_classes=3, dropout=0.4):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_dim),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, num_classes)
        )

    def forward(self, x):
        return self.classifier(x)


class CompletePDModel(nn.Module):
    """Complete model: Fused Encoder + Classifier"""
    def __init__(self, fused_encoder, classifier):
        super().__init__()
        self.fused_encoder = fused_encoder
        self.classifier = classifier

    def forward(self, motor_x, nonmotor_x, imaging_x):
        fused_emb, individual_embs = self.fused_encoder(motor_x, nonmotor_x, imaging_x)
        logits = self.classifier(fused_emb)
        return logits, fused_emb, individual_embs


# ============================================================================
# BASELINE MODELS (Included for completeness, not used in main execution)
# ============================================================================

class LSTMLateBaseline(nn.Module):
    """LSTM + Late Fusion baseline"""
    def __init__(self, motor_dim=14, nonmotor_embed_dim=32, imaging_dim=147):
        super().__init__()
        # Motor: (batch, 1, 14) -> (batch, 1, 32) -> (batch, 32)
        self.motor_lstm = nn.LSTM(motor_dim, 32, batch_first=True)
        # Non-motor: The original script used nonmotor_x[0] which is the first sequence category
        # Assuming the first category is ~101 dim and embed_dim is 32*2=64 in the original design,
        # but here we use a simplified late fusion for the placeholder.
        self.nonmotor_lstm = nn.LSTM(101, 32, batch_first=True)
        self.imaging_fc = nn.Linear(imaging_dim, 32)
        self.classifier = nn.Linear(32 * 3, 3) # 32 motor + 32 non-motor + 32 imaging = 96

    def forward(self, motor_x, nonmotor_x, imaging_x):
        # Motor: (batch, 14) -> (batch, 1, 14) for LSTM
        motor_out, _ = self.motor_lstm(motor_x.unsqueeze(1))
        motor_feat = motor_out[:, -1, :] # Last time step output

        # Non-motor: Use the first non-motor sequence (x_list[0])
        nm_out, _ = self.nonmotor_lstm(nonmotor_x[0])
        nm_feat = nm_out.mean(dim=1) # Mean pooling over sequence length

        # Imaging
        img_feat = self.imaging_fc(imaging_x)

        fused = torch.cat([motor_feat, nm_feat, img_feat], dim=1) # (batch, 96)
        return self.classifier(fused)


# ============================================================================
# DATASET CLASS
# ============================================================================

class MultimodalParkinsonsDataset(Dataset):
    """Complete multimodal dataset with proper preprocessing"""
    def __init__(self, motor_df, nonmotor_seqs, imaging_df, patient_ids, labels_df):
        self.motor_df = motor_df
        # nonmotor_seqs is a list of tuples, where each tuple contains 5 non-motor sequence tensors
        self.nonmotor_seqs = nonmotor_seqs
        self.imaging_df = imaging_df
        self.patient_ids = list(patient_ids)
        self.labels_df = labels_df
        self.label_map = dict(zip(labels_df['PATNO'], labels_df['label']))
        self.motor_cols = None # To be set by load_and_preprocess_all_data
        self.imaging_cols = None # To be set by load_and_preprocess_all_data
        print(f"✓ Dataset initialized: {len(self.patient_ids)} patients")

    def __len__(self):
        return len(self.patient_ids)

    def __getitem__(self, idx):
        patient_id = self.patient_ids[idx]

        # Motor features (static/visit-specific)
        motor_row = self.motor_df[self.motor_df['PATNO'] == patient_id].iloc[0]
        motor_values = motor_row[self.motor_cols].values.astype(np.float32)
        motor_features = torch.tensor(motor_values, dtype=torch.float32)

        # Non-motor sequences (tuple of 5 tensors)
        nonmotor_tuple = self.nonmotor_seqs[idx] # Already a tuple of tensors

        # Imaging features (static/visit-specific)
        imaging_row = self.imaging_df[self.imaging_df['PATNO'] == patient_id].iloc[0]
        imaging_values = imaging_row[self.imaging_cols].values.astype(np.float32)
        imaging_features = torch.tensor(imaging_values, dtype=torch.float32)

        label = self.label_map.get(patient_id, 0)

        # The NonMotorEncoder expects a tuple of tensors, so we return the tuple directly
        return motor_features, nonmotor_tuple, imaging_features, patient_id


# ============================================================================
# HELPER FUNCTION TO LOAD ENCODER WITH DIMENSION CHECK
# ============================================================================

def load_encoder_with_check(encoder, weight_path, device):
    """Load encoder weights with dimension mismatch handling"""
    try:
        # Try to load directly
        # Must ensure the weights are loaded to the correct device
        state_dict = torch.load(weight_path, map_location=device)

        # This check is crucial for the Transformer Motor Encoder if it was trained on a different version
        # It attempts to fix common state_dict key discrepancies if the model definition changed slightly
        new_state_dict = {}
        for k, v in state_dict.items():
            # Handle potential mismatch in key names from older PyTorch versions
            if k.startswith('module.'):
                k = k[7:]  # remove 'module.' prefix if it exists
            new_state_dict[k] = v

        encoder.load_state_dict(new_state_dict, strict=True)
        print(f"✓ Loaded weights from {weight_path}")
        return True
    except RuntimeError as e:
        if "size mismatch" in str(e) or "Missing key(s)" in str(e) or "Unexpected key(s)" in str(e):
            print(f"⚠ Warning: Dimension or key mismatch detected in {weight_path}")
            print(f"  {str(e)[:200]}...")
            # Attempt a non-strict load if it's a size mismatch on final layers, otherwise use random init
            # Since the problem asks for a fixed version, we stick to the simpler (safer) random init
            print(f"  Initializing encoder with random weights instead")
            return False
        else:
            raise e


# ============================================================================
# DATA LOADING AND PREPROCESSING
# ============================================================================
def load_and_preprocess_all_data():
    """Load all datasets and prepare them"""
    print("\n" + "="*70)
    print("LOADING AND PREPROCESSING DATA")
    print("="*70)

    # Load motor data
    print("\n1. Loading motor data...")
    df_motor = pd.read_parquet('motor.parquet', engine='pyarrow')
    motor_cols = ['NP2SPCH', 'NP2SALV', 'NP2SWAL', 'NP2EAT', 'NP2DRES', 'NP2HYGN',
                  'NP2HWRT', 'NP2HOBB', 'NP2TURN', 'NP2TRMR', 'NP2RISE', 'NP2WALK',
                  'NP2FREZ', 'Total_Motor_Score']

    motor_patients = set(df_motor['PATNO'].unique())

    # Ensure all motor columns are numeric
    for col in motor_cols:
        df_motor[col] = pd.to_numeric(df_motor[col], errors='coerce')

    imputer_motor = SimpleImputer(strategy='mean')
    df_motor[motor_cols] = imputer_motor.fit_transform(df_motor[motor_cols])
    scaler_motor = StandardScaler()
    df_motor[motor_cols] = scaler_motor.fit_transform(df_motor[motor_cols])

    df_motor[motor_cols] = df_motor[motor_cols].astype(np.float32)

    # Select the latest visit for static features
    df_motor = df_motor.sort_values(['PATNO', 'EVENT_ID']).groupby('PATNO').tail(1).reset_index(drop=True)

    print(f"   ✓ Motor: {len(df_motor)} patients, {len(motor_cols)} features")

    # Load non-motor data
    print("\n2. Loading non-motor data...")
    df_cog = pd.read_parquet('cog.parquet', engine='pyarrow')
    df_psych = pd.read_parquet('merged_df.parquet', engine='pyarrow')
    df_sleep = pd.read_parquet('df2_Selected.parquet', engine='pyarrow')
    df_auto = pd.read_parquet('Merged_Df.parquet', engine='pyarrow')
    df_sens = pd.read_parquet('sleep.parquet', engine='pyarrow')

    # Non-numeric columns to be ignored (but NOT PATNO and EVENT_ID for grouping)
    non_numeric_cols = ['REC_ID_x', 'PAG_NAME_x', 'INFODT_x', 'BIRTHDT', 'CLIA', 'GWAS',
                       'WES', 'WGS', 'SVs', 'SANGER', 'IU_Fingerprint', 'RNASEQ', 'APOE',
                       'REC_ID', 'INFODT', 'PAG_NAME']

    def preprocess_keep_numeric(df, drop_cols):
        """Preprocess sequences while keeping PATNO and EVENT_ID for grouping"""
        df = df.sort_values(['PATNO', 'EVENT_ID'])

        # Drop non-numeric columns (but keep PATNO and EVENT_ID)
        cols_to_drop = [c for c in drop_cols if c in df.columns and c not in ['PATNO', 'EVENT_ID']]
        df = df.drop(columns=cols_to_drop, errors='ignore')

        # Identify feature columns (exclude PATNO and EVENT_ID)
        feat_cols = [c for c in df.columns if c not in ['PATNO', 'EVENT_ID']]

        # Convert to numeric and fill NaN
        for col in feat_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # Scale features within each patient group
        scaler_seq = StandardScaler()
        for col in feat_cols:
            df[col] = df.groupby('PATNO')[col].transform(
                lambda x: scaler_seq.fit_transform(x.fillna(0).values.reshape(-1, 1)).flatten()
            )

        df[feat_cols] = df[feat_cols].fillna(0).astype('float32')

        return df, feat_cols

    def create_sequences(df, feat_cols, max_seq_len=10):
        """Create fixed-length sequences for each patient"""
        seqs, pat_list = [], []
        for pid, grp in df.groupby('PATNO'):
            data = grp.sort_values('EVENT_ID')[feat_cols].to_numpy(dtype=np.float32)
            t = torch.tensor(data)
            if t.size(0) < max_seq_len:
                # Pad with zeros at the end
                pad = torch.zeros(max_seq_len - t.size(0), t.size(1))
                t = torch.cat([t, pad], dim=0)
            else:
                # Truncate to max_seq_len
                t = t[:max_seq_len]
            seqs.append(t)
            pat_list.append(pid)
        return seqs, pat_list

    # Process all non-motor modalities
    dfs = [df_cog, df_psych, df_sleep, df_auto, df_sens]
    processed, feature_cols_list = [], []

    for i, df in enumerate(dfs):
        print(f"   Processing non-motor modality {i+1}/5...")
        df2, fcols = preprocess_keep_numeric(df, non_numeric_cols)
        processed.append(df2)
        feature_cols_list.append(fcols)
        print(f"     ✓ Features: {len(fcols)}")

    # Create sequences for each modality
    seqs_list, patno_lists = [], []
    for df, cols in zip(processed, feature_cols_list):
        seqs, pats = create_sequences(df, cols)
        seqs_list.append(seqs)
        patno_lists.append(pats)

    # Get union of all patients across non-motor modalities
    all_patnos_nm = sorted(set().union(*[set(pl) for pl in patno_lists]))

    # Align sequences to the union of all non-motor patients
    aligned_seqs = []
    for i, (mod_seqs, mod_patnos) in enumerate(zip(seqs_list, patno_lists)):
        pid_to_seq = dict(zip(mod_patnos, mod_seqs))

        # Get dimensions for padding
        if mod_seqs:
            feat_dim = mod_seqs[0].size(1)
            seq_len = mod_seqs[0].size(0)
        else:
            feat_dim = len(feature_cols_list[i])
            seq_len = 10  # Default max_seq_len

        aligned = []
        for pid in all_patnos_nm:
            if pid in pid_to_seq:
                aligned.append(pid_to_seq[pid])
            else:
                # Create a zero tensor for patients missing this modality
                aligned.append(torch.zeros(seq_len, feat_dim, dtype=torch.float32))

        aligned_seqs.append(aligned)

    nonmotor_patients = set(all_patnos_nm)
    print(f"   ✓ Non-motor: {len(nonmotor_patients)} patients")
    input_dims_nm = [len(cols) for cols in feature_cols_list]
    print(f"   ✓ Non-motor feature dimensions: {input_dims_nm}")

    # Load imaging data
    print("\n3. Loading imaging data...")
    df_dti = pd.read_parquet('dti.parquet', engine='pyarrow')
    df_mri = pd.read_parquet('mri.parquet', engine='pyarrow')

    # DTI Processing - Pivot from long to wide format
    # DTI has: PATNO, Measure (E1/E2/E3), Tissue (SN), ROI1-6, REF1-2
    print("   Processing DTI data...")
    value_cols = ['ROI1', 'ROI2', 'ROI3', 'ROI4', 'ROI5', 'ROI6', 'REF1', 'REF2']

    # Pivot: each Measure (E1, E2, E3) becomes separate columns for each ROI
    dti_pivot = df_dti.pivot_table(
        index='PATNO',
        columns='Measure',
        values=value_cols,
        aggfunc='mean'  # Average if multiple tissue types per patient
    )

    # Flatten column names: (ROI1, E1) -> ROI1_E1
    dti_pivot.columns = ['_'.join(map(str, col)) for col in dti_pivot.columns.values]
    dti_pivot = dti_pivot.reset_index()

    # Remove rows with too many missing values
    dti_cols = [col for col in dti_pivot.columns if col != 'PATNO']
    dti_pivot = dti_pivot.dropna(thresh=len(dti_cols) * 0.5)  # Keep rows with at least 50% non-null

    print(f"   ✓ DTI: {len(dti_pivot)} patients, {len(dti_cols)} features")

    # MRI Processing - Select anatomical features and latest visit
    print("   Processing MRI data...")
    anatomical_cols = [col for col in df_mri.columns if col.startswith((
        'lh_', 'rh_', 'Left_', 'Right_',
        'BrainSeg', 'Cortex', 'CC_', 'Cerebellum', 'Ventricle',
        'Thalamus', 'Caudate', 'Putamen', 'Pallidum',
        'Hippocampus', 'Amygdala', 'Accumbens'
    )) and col not in ['lhSurfaceHoles', 'rhSurfaceHoles']]

    # Select base columns and anatomical features
    mri_features = df_mri[['PATNO', 'EVENT_ID'] + anatomical_cols].copy()

    # Get latest visit per patient
    mri_features = mri_features.sort_values(['PATNO', 'EVENT_ID']).groupby('PATNO').tail(1).reset_index(drop=True)

    # Drop EVENT_ID after selection
    mri_features = mri_features.drop(columns=['EVENT_ID'])

    print(f"   ✓ MRI: {len(mri_features)} patients, {len(anatomical_cols)} features")

    # Merge DTI and MRI on PATNO
    df_imaging = dti_pivot.merge(mri_features, on='PATNO', how='inner')
    print(f"   ✓ Combined imaging: {len(df_imaging)} patients after merge")

    # Identify all imaging feature columns (exclude ID columns)
    id_cols = ['PATNO', 'EVENT_ID', 'VISCODE', 'EXAMDATE']
    imaging_cols = [col for col in df_imaging.columns if col not in id_cols]

    # Remove columns that are all NaN or have too many missing values
    missing_pct = df_imaging[imaging_cols].isnull().sum() / len(df_imaging)
    valid_cols = missing_pct[missing_pct < 0.8].index.tolist()  # Keep columns with <80% missing

    if len(valid_cols) < len(imaging_cols):
        print(f"   ⚠ Removed {len(imaging_cols) - len(valid_cols)} columns with >80% missing values")
        imaging_cols = valid_cols

    print(f"   ✓ Found {len(imaging_cols)} valid imaging features")

    # Convert to numeric and handle any remaining non-numeric values
    for col in imaging_cols:
        df_imaging[col] = pd.to_numeric(df_imaging[col], errors='coerce')

    # Impute and scale imaging features
    imputer_imaging = SimpleImputer(strategy='mean')
    imaging_imputed = imputer_imaging.fit_transform(df_imaging[imaging_cols])

    scaler_imaging = StandardScaler()
    imaging_scaled = scaler_imaging.fit_transform(imaging_imputed)

    # Update dataframe with scaled values
    df_imaging[imaging_cols] = imaging_scaled.astype(np.float32)

    imaging_patients = set(df_imaging['PATNO'].unique())
    print(f"   ✓ Imaging: {len(imaging_patients)} patients, {len(imaging_cols)} features")

    # Determine common patients and labels
    common_patients = motor_patients & nonmotor_patients & imaging_patients
    print(f"\n4. Common patients across all modalities: {len(common_patients)}")

    # Create labels
    print("\n5. Creating labels...")
    visit_phase_mapping = {
        'BL':'early', 'R17':'early', 'SC':'early', 'R16':'early', 'R15':'early',
        'R13':'early', 'LOG':'early', 'R08':'early', 'R10':'early', 'R12':'early',
        'R06':'early', 'R04':'early', 'R01':'early', 'PW':'early',
        'TRANS':'mid', 'V01':'mid', 'V02':'mid', 'V03':'mid', 'V04':'mid',
        'V05':'mid', 'V06':'mid', 'ST':'mid', 'RS1':'mid', 'R21':'mid',
        'U02':'mid', 'U01':'mid', 'R19':'mid', 'R20':'mid', 'R14':'mid',
        'V07':'late', 'V08':'late', 'V09':'late', 'V10':'late', 'V11':'late',
        'V12':'late', 'V13':'late', 'V14':'late', 'V15':'late', 'V16':'late',
        'V17':'late', 'V18':'late', 'V19':'late', 'V20':'late', 'V21':'late',
        'V22':'late', 'R18':'late'
    }
    stage_mapping = {'early': 0, 'mid': 1, 'late': 2}

    # Use all unique events across non-motor data
    all_events = pd.concat([df[['PATNO','EVENT_ID']] for df in processed]).drop_duplicates()
    all_events['stage_str'] = all_events['EVENT_ID'].map(visit_phase_mapping)
    latest = all_events.sort_values('EVENT_ID').groupby('PATNO').tail(1).reset_index(drop=True)
    labels_df = latest[['PATNO','stage_str']].copy()
    labels_df['label'] = labels_df['stage_str'].map(stage_mapping)
    labels_df = labels_df[labels_df['PATNO'].isin(common_patients)]

    common_patients = sorted(list(common_patients))

    # Filter and align data for final common patients
    df_motor_filtered = df_motor[df_motor['PATNO'].isin(common_patients)].sort_values('PATNO')
    df_imaging_filtered = df_imaging[df_imaging['PATNO'].isin(common_patients)].sort_values('PATNO')

    # Re-align nonmotor sequences
    nm_patient_to_idx = {pid: i for i, pid in enumerate(all_patnos_nm)}
    aligned_nm_seqs_filtered = []

    for pid in common_patients:
        idx = nm_patient_to_idx[pid]
        patient_tuple = tuple(modality_list[idx] for modality_list in aligned_seqs)
        aligned_nm_seqs_filtered.append(patient_tuple)

    print(f"   ✓ Labels created for {len(labels_df)} common patients")
    print(f"   ✓ Label distribution: {dict(labels_df['label'].value_counts())}")

    return {
        'motor_df': df_motor_filtered,
        'motor_cols': motor_cols,
        'nonmotor_seqs': aligned_nm_seqs_filtered,
        'imaging_df': df_imaging_filtered,
        'imaging_cols': imaging_cols,
        'patient_ids': common_patients,
        'labels_df': labels_df,
        'input_dims_nm': input_dims_nm,
        'embed_dims_nm': [16, 16, 12, 12, 8]
    }
# ============================================================================
# TRAINING FUNCTIONS
# ============================================================================

def train_epoch(model, dataloader, criterion, optimizer, device):
    model.train()
    total_loss, correct, total = 0, 0, 0

    for motor_x, nonmotor_x, imaging_x, patient_ids in tqdm(dataloader, desc="Training", leave=False):
        motor_x = motor_x.to(device)
        nonmotor_x = tuple(x.to(device) for x in nonmotor_x)
        imaging_x = imaging_x.to(device)

        # Get labels using the patient IDs and the dataset's label map
        labels = torch.tensor([dataloader.dataset.dataset.label_map[pid] for pid in patient_ids], dtype=torch.long).to(device)

        optimizer.zero_grad()
        logits, _, _ = model(motor_x, nonmotor_x, imaging_x)
        loss = criterion(logits, labels)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        total_loss += loss.item()
        preds = torch.argmax(logits, dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    return total_loss / len(dataloader), correct / total


def validate_epoch(model, dataloader, criterion, device):
    model.eval()
    total_loss = 0
    all_preds, all_labels, all_probs = [], [], []

    with torch.no_grad():
        for motor_x, nonmotor_x, imaging_x, patient_ids in tqdm(dataloader, desc="Validating", leave=False):
            motor_x = motor_x.to(device)
            nonmotor_x = tuple(x.to(device) for x in nonmotor_x)
            imaging_x = imaging_x.to(device)

            labels = torch.tensor([dataloader.dataset.dataset.label_map[pid] for pid in patient_ids], dtype=torch.long).to(device)

            logits, _, _ = model(motor_x, nonmotor_x, imaging_x)
            loss = criterion(logits, labels)
            total_loss += loss.item()

            probs = F.softmax(logits, dim=1)
            preds = torch.argmax(logits, dim=1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    avg_loss = total_loss / len(dataloader)
    accuracy = accuracy_score(all_labels, all_preds)

    return avg_loss, accuracy, all_preds, all_labels, np.array(all_probs)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    print("\n" + "="*70)
    print("PARKINSON'S DISEASE COMPLETE TRAINING PIPELINE")
    print("="*70)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nDevice: {device}")

    # Step 1: Load and preprocess data
    data_dict = load_and_preprocess_all_data()

    # Step 2: Create dataset
    print("\n" + "="*70)
    print("CREATING DATASET")
    print("="*70)

    dataset = MultimodalParkinsonsDataset(
        motor_df=data_dict['motor_df'],
        nonmotor_seqs=data_dict['nonmotor_seqs'],
        imaging_df=data_dict['imaging_df'],
        patient_ids=data_dict['patient_ids'],
        labels_df=data_dict['labels_df']
    )
    dataset.motor_cols = data_dict['motor_cols']
    dataset.imaging_cols = data_dict['imaging_cols']

    # Step 3: Load master split
    print("\n" + "="*70)
    print("LOADING MASTER PATIENT SPLIT")
    print("="*70)

    try:
        with open('master_patient_split.pkl', 'rb') as f:
            split_data = pickle.load(f)
    except FileNotFoundError:
        print("Error: 'master_patient_split.pkl' not found. Please run the prerequisite script.")
        return

    train_patients = set(split_data['train_patients'])
    val_patients = set(split_data['val_patients'])
    test_patients = set(split_data['test_patients'])

    # Filter indices based on patients present in the final, common dataset
    train_indices = [i for i, pid in enumerate(dataset.patient_ids) if pid in train_patients]
    val_indices = [i for i, pid in enumerate(dataset.patient_ids) if pid in val_patients]
    test_indices = [i for i, pid in enumerate(dataset.patient_ids) if pid in test_patients]

    print(f"Train: {len(train_indices)} | Val: {len(val_indices)} | Test: {len(test_indices)}")

    # Step 4: Create data loaders
    BATCH_SIZE = 8

    train_subset = torch.utils.data.Subset(dataset, train_indices)
    val_subset = torch.utils.data.Subset(dataset, val_indices)
    test_subset = torch.utils.data.Subset(dataset, test_indices)

    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)
    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)
    test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)

    # Step 5: Load encoders with dimension checking
    print("\n" + "="*70)
    print("LOADING PRE-TRAINED ENCODERS")
    print("="*70)

    # Motor encoder (input_dim=14, latent_dim=16)
    motor_encoder = TransformerMotorEncoder(input_dim=len(data_dict['motor_cols']), latent_dim=16).to(device)
    motor_loaded = load_encoder_with_check(motor_encoder, 'motor_encoder_weights.pth', device)

    # Non-motor encoder with current data dimensions
    nonmotor_encoder = NonMotorEncoder(data_dict['input_dims_nm'], data_dict['embed_dims_nm'], common_dim=16).to(device)
    nonmotor_loaded = load_encoder_with_check(nonmotor_encoder, 'nonmotor_encoder_weights.pth', device)

    # Imaging encoder (input_dim=len(imaging_cols), latent_dim=16)
    imaging_encoder = ImagingEncoder(len(data_dict['imaging_cols']), latent_dim=16).to(device)
    imaging_loaded = load_encoder_with_check(imaging_encoder, 'imaging_encoder_weights.pth', device)

    if not (motor_loaded and nonmotor_loaded and imaging_loaded):
        print("\n⚠ Warning: Some encoders using random initialization due to dimension mismatch or missing files.")
        print("  Training will proceed with uninitialized or partially initialized weights.")

    # Step 6: Create fused encoder
    print("\n" + "="*70)
    print("CREATING FUSED ENCODER")
    print("="*70)

    fused_encoder = UnifiedFusedEncoder(motor_encoder, nonmotor_encoder, imaging_encoder, latent_dim=16, freeze_encoders=True).to(device)
    print(f"✓ Fused encoder created (output dim: {fused_encoder.get_embedding_dim()})")

    # Step 7: Create classifier
    classifier = PDStageClassifier(input_dim=48, hidden_dim=128, num_classes=3, dropout=0.4).to(device)
    model = CompletePDModel(fused_encoder, classifier).to(device)

    # Step 8: Setup training
    print("\n" + "="*70)
    print("TRAINING SETUP")
    print("="*70)

    train_labels = [dataset.label_map[dataset.patient_ids[i]] for i in train_indices]
    class_counts = np.bincount(train_labels, minlength=3)
    # Calculate inverse class frequency weights
    class_weights = torch.FloatTensor(len(train_labels) / (3 * class_counts)).to(device)
    criterion = nn.CrossEntropyLoss(weight=class_weights)

    # Only optimize the classifier parameters and fusion parameters if encoders are frozen
    optimizer_params = [
        {'params': model.classifier.parameters()},
        {'params': model.fused_encoder.fusion.parameters()}
    ]
    if not fused_encoder.fused_encoder.freeze_encoders:
        optimizer_params.append({'params': model.fused_encoder.motor_encoder.parameters()})
        optimizer_params.append({'params': model.fused_encoder.nonmotor_encoder.parameters()})
        optimizer_params.append({'params': model.fused_encoder.imaging_encoder.parameters()})

    optimizer = torch.optim.Adam(optimizer_params, lr=1e-3)

    print(f"Class counts: {class_counts}")
    print(f"Class weights: {class_weights.cpu().numpy()}")

    # Step 9: Training loop
    print("\n" + "="*70)
    print("TRAINING")
    print("="*70)

    best_val_acc = 0
    patience_counter = 0
    patience = 15
    num_epochs = 100

    train_losses, val_losses = [], []
    train_accs, val_accs = [], []

    for epoch in range(num_epochs):
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
        val_loss, val_acc, _, _, _ = validate_epoch(model, val_loader, criterion, device)

        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)

        print(f"Epoch {epoch+1:3d}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc*100:5.1f}% | Val Loss: {val_loss:.4f} Acc: {val_acc*100:5.1f}%")

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'val_loss': val_loss
            }, 'best_complete_model.pth')
            print(f"  ✓ Best model saved (Val Acc: {val_acc*100:.1f}%)")
        else:
            patience_counter += 1

        if patience_counter >= patience:
            print(f"\nEarly stopping at epoch {epoch+1}")
            break

    # Step 10: Load best model and evaluate

    print("\n" + "="*70)
    print("FINAL EVALUATION ON TEST SET")
    print("="*70)

    try:
        checkpoint = torch.load('best_complete_model.pth', map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
    except FileNotFoundError:
        print("Warning: Best model checkpoint not found. Evaluating with last epoch weights.")

    test_loss, test_acc, test_preds, test_labels, test_probs = validate_epoch(model, test_loader, criterion, device)

    # Filter metrics to only include classes present in the test set
    stage_names = ['Early', 'Mid', 'Late']
    unique_labels = np.unique(test_labels)

    precision, recall, f1, support = precision_recall_fscore_support(test_labels, test_preds,
                                                                   labels=[0, 1, 2], average=None, zero_division=0)
    macro_f1 = f1_score(test_labels, test_preds, average='macro', zero_division=0)

    # AUC calculation
    try:
        if test_probs.shape[1] == 3:
            auc = roc_auc_score(test_labels, test_probs, multi_class='ovr', average='macro', labels=[0, 1, 2])
        else:
            auc = 0.0
            print("Warning: AUC calculation skipped due to missing class probabilities")
    except Exception as e:
        auc = 0.0
        print(f"Warning: AUC calculation failed: {e}")

    cm = confusion_matrix(test_labels, test_preds, labels=[0, 1, 2])


    print(f"\nTest Results:")
    print(f"  Accuracy: {test_acc*100:.1f}%")
    print(f"  Macro F1: {macro_f1*100:.1f}%")
    print(f"  AUC: {auc:.3f}")

    print(f"\nPer-Class Metrics:")
    for i, stage in enumerate(stage_names):
        print(f"  {stage}:")
        print(f"    Precision: {precision[i]*100:.1f}%")
        print(f"    Recall: {recall[i]*100:.1f}%")
        print(f"    F1-Score: {f1[i]*100:.1f}%")
        print(f"    Support: {support[i]}")

    print(f"\nConfusion Matrix:")
    print(cm)

    # Step 11: Visualizations (Completed Code)
    print("\n" + "="*70)
    print("GENERATING VISUALIZATIONS")
    print("="*70)

    # Confusion matrix
    cm_pct = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8) * 100
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm_pct, annot=True, fmt='.1f', cmap='Blues',
                xticklabels=stage_names, yticklabels=stage_names,
                cbar_kws={'label': 'Percentage (%)'})
    plt.title('Test Set Confusion Matrix (%)', fontsize=14, fontweight='bold')
    plt.ylabel('True Stage', fontsize=12)
    plt.xlabel('Predicted Stage', fontsize=12)
    plt.tight_layout()
    plt.savefig('confusion_matrix_test.png', dpi=300, bbox_inches='tight')
    print("✓ Saved: confusion_matrix_test.png")
    plt.close()

    # Training curves
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    epochs = range(1, len(train_losses) + 1)

    # Loss Plot
    axes[0].plot(epochs, train_losses, label='Train', linewidth=2)
    axes[0].plot(epochs, val_losses, label='Validation', linewidth=2, linestyle='--')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')
    axes[0].legend(fontsize=10)
    axes[0].grid(True, alpha=0.3)

    # Accuracy Plot (Completes the truncated code from the prompt)
    axes[1].plot(epochs, train_accs, label='Train', linewidth=2)
    axes[1].plot(epochs, val_accs, label='Validation', linewidth=2, linestyle='--')
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy', fontsize=12)
    axes[1].set_title('Training vs Validation Accuracy', fontsize=14, fontweight='bold')
    axes[1].legend(fontsize=10)
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
    print("✓ Saved: training_curves.png")
    plt.close(fig)

    # Step 12: SHAP Analysis for Feature Importance
    if SHAP_AVAILABLE:
        print("\n" + "="*70)
        print("SHAP FEATURE IMPORTANCE ANALYSIS (Latent Space)")
        print("="*70)

        try:
            # 1. Collect all fused embeddings from the test set
            model.eval()
            test_fused_embs = []
            for motor_x, nonmotor_x, imaging_x, _ in test_loader:
                motor_x = motor_x.to(device)
                nonmotor_x = tuple(x.to(device) for x in nonmotor_x)
                imaging_x = imaging_x.to(device)
                _, fused_emb, _ = model.fused_encoder(motor_x, nonmotor_x, imaging_x)
                test_fused_embs.append(fused_emb.cpu().numpy())

            test_fused_embs = np.concatenate(test_fused_embs, axis=0)

            # 2. Define latent feature names for interpretability
            feature_names = [f"Motor_Emb_{i+1}" for i in range(16)] + \
                            [f"NM_Emb_{i+1}" for i in range(16)] + \
                            [f"Img_Emb_{i+1}" for i in range(16)]

            # 3. Create a callable prediction function for SHAP (Classifier only)
            def classifier_predict(X):
                # X is numpy array of shape (N, 48)
                X_tensor = torch.tensor(X, dtype=torch.float32).to(device)
                with torch.no_grad():
                    logits = model.classifier(X_tensor)
                    return logits.cpu().numpy()

            # 4. Use KernelExplainer (suitable for complex, non-linear models)
            # Use a sample of the test set for background for faster computation
            background_data = shap.maskers.Independent(test_fused_embs, max_samples=100)
            explainer = shap.KernelExplainer(classifier_predict, background_data)

            # 5. Calculate SHAP values for the entire test set
            # This can be slow; consider using a subset of the test_fused_embs if needed
            print("  Calculating SHAP values (This may take some time)...")
            shap_values_list = explainer.shap_values(test_fused_embs)

            # 6. Generate Summary Plot
            # shap_values_list is a list of arrays (one for each class: 0, 1, 2)
            shap.summary_plot(shap_values_list, test_fused_embs, feature_names=feature_names,
                              class_names=stage_names, title="SHAP Summary Plot (Fused Latent Features)",
                              show=False)
            plt.savefig('shap_summary_all_classes.png', dpi=300, bbox_inches='tight')
            print("✓ Saved: shap_summary_all_classes.png (for latent features)")
            plt.close()

        except Exception as e:
            print(f"⚠ SHAP analysis failed: {e}")
            print("  Ensure all dependencies are correctly installed and the model is not too large for SHAP.")

    print("\n" + "="*70)
    print("PIPELINE COMPLETE")
    print("="*70)

if __name__ == '__main__':
    # Execute the main function when the script is run
    main()

"""
Quick data inspector to check parquet file structures
Run this to understand your data before processing
"""

import pandas as pd
import os

def inspect_parquet_file(filename):
    """Inspect a parquet file and print useful information"""
    if not os.path.exists(filename):
        print(f"❌ {filename} not found")
        return

    print(f"\n{'='*70}")
    print(f"FILE: {filename}")
    print(f"{'='*70}")

    try:
        df = pd.read_parquet(filename, engine='pyarrow')

        print(f"Shape: {df.shape[0]} rows × {df.shape[1]} columns")
        print(f"\nColumns ({len(df.columns)}):")
        print(df.columns.tolist())

        print(f"\nFirst few rows:")
        print(df.head(3))

        print(f"\nData types:")
        print(df.dtypes.value_counts())

        # Check for key columns
        key_cols = ['PATNO', 'EVENT_ID', 'VISCODE', 'EXAMDATE', 'Measure']
        present_keys = [col for col in key_cols if col in df.columns]
        print(f"\nKey columns present: {present_keys}")

        if 'PATNO' in df.columns:
            print(f"Unique patients: {df['PATNO'].nunique()}")

        # Check for missing values
        missing = df.isnull().sum()
        if missing.sum() > 0:
            print(f"\nColumns with missing values (top 10):")
            print(missing[missing > 0].sort_values(ascending=False).head(10))

    except Exception as e:
        print(f"❌ Error reading {filename}: {e}")

# List of files to inspect
files = [
    'motor.parquet',
    'cog.parquet',
    'merged_df.parquet',
    'df2_Selected.parquet',
    'Merged_Df.parquet',
    'sleep.parquet',
    'dti.parquet',
    'mri.parquet'
]

print("="*70)
print("PARKINSON'S DATA FILE INSPECTOR")
print("="*70)

for filename in files:
    inspect_parquet_file(filename)

print("\n" + "="*70)
print("INSPECTION COMPLETE")
print("="*70)

import sys

def print_simulated_output():
    """Prints the hardcoded, simulated model inference output to the console."""

    # --- SIMULATED DATA ---
    patno = "A001"
    visit = "V02"
    diagnosis = "EARLY STAGE PARKINSON'S DISEASE"
    confidence = "93.8%"

    # Attention weights: The core finding that Imaging (47%) > Non-Motor (37%) > Motor (16%)
    weights = [
        ("IMAGING", "47%", "DTI - Substantia Nigra (Low FA value)"),
        ("NON-MOTOR", "37%", "Sleep Status (RBD) (Confirmed)"),
        ("MOTOR", "16%", "NP2WALK (Walking - Score 1)")
    ]

    # --- PRINTING TO CONSOLE ---
    sys.stdout.write(f"$ python multimodal_pd_predictor.py --patno {patno} --visit {visit}\n\n")
    sys.stdout.write("====================================================================\n")
    sys.stdout.write("SEQUENTIAL MULTIMODAL PD RISK ASSESSMENT FRAMEWORK\n")
    sys.stdout.write(f"(Inference Run: 2025-11-06 11:30:04 IST)\n")
    sys.stdout.write("====================================================================\n\n")

    sys.stdout.write(f"--- INPUT SUMMARY (Patient {patno} / Baseline + 6 Months) ---\n")
    sys.stdout.write("| Modality | Input Vector Status | Key Clinical Score |\n")
    sys.stdout.write("|----------|---------------------|--------------------|\n")
    sys.stdout.write("| IMAGING  | VAE Encoded 16D     | DTI Status: Anomalous |\n")
    sys.stdout.write("| NON-MOTOR| VAE Encoded 16D     | PDAQ Score: 8/40 |\n")
    sys.stdout.write("| MOTOR    | Transformer 16D     | MDS-UPDRS II: 2.0 |\n")
    sys.stdout.write("--------------------------------------------------------------------\n\n")

    sys.stdout.write("--- FINAL PREDICTION ---\n")
    sys.stdout.write(f"DIAGNOSIS:               {diagnosis}\n")
    sys.stdout.write(f"PREDICTION CONFIDENCE:   {confidence}\n")
    sys.stdout.write("--------------------------------------------------------------------\n\n")

    sys.stdout.write("--- INTERPRETABILITY: MODALITY CONTRIBUTION (ATTENTION WEIGHTS) ---\n")
    sys.stdout.write("(Explaining *why* the prediction was made: Total must sum to 100%)\n")
    sys.stdout.write("| Modality | Contribution (%) | Specific Feature Highlight |\n")
    sys.stdout.write("|----------|------------------|----------------------------|\n")

    # Print the weights, bolding the key IMAGING feature
    for modality, contribution, highlight in weights:
        if modality == "IMAGING":
            sys.stdout.write(f"| **{modality:<8}** | **{contribution:<16}** | **{highlight:<26}** |\n")
        else:
            sys.stdout.write(f"| {modality:<8} | {contribution:<16} | {highlight:<26} |\n")

    sys.stdout.write("--------------------------------------------------------------------\n")
    sys.stdout.write(f"*Rationale: The model's decision for 'Early Stage' is primarily driven by the IMAGING encoder's detection of structural pathology, consistent with the pre-motor phase of PD. Non-Motor contribution validates the prodromal phase.*\n\n")

    sys.stdout.write("--- NEXT CLINICAL ACTION ---\n")
    sys.stdout.write("RECOMMENDATION: Schedule follow-up imaging (MRI/DTI) within 6 months. Monitor Non-Motor symptoms closely.\n")
    sys.stdout.write("MODEL TRAJECTORY: Predicted transition to Mid-Stage within 30-48 months (p=0.74).\n\n")
    sys.stdout.write("$ _\n")


if __name__ == "__main__":
    print_simulated_output()

"""
Parkinson's Disease Stage Prediction - Clinical Inference Output
Simulates realistic command-line output for unseen patient data
"""

import time
import sys

def print_header():
    print("\n")
    print(" "*20 + "PARKINSON'S DISEASE STAGE PREDICTION SYSTEM")
    print(" "*25 + "Multimodal Deep Learning Framework")
    print("="*80 + "\n")

def simulate_loading():
    print("Loading pre-trained models...")
    time.sleep(0.3)
    print("  ✓ Motor Encoder (Transformer, 16-dim) loaded")
    time.sleep(0.2)
    print("  ✓ Non-Motor Encoder (LSTM-based, 16-dim) loaded")
    time.sleep(0.2)
    print("  ✓ Imaging Encoder (VAE, 16-dim) loaded")
    time.sleep(0.2)
    print("  ✓ Attention Fusion Layer (48-dim output) loaded")
    time.sleep(0.2)
    print("  ✓ Stage Classifier (3-class) loaded")
    print("\nAll models loaded successfully!\n")
    time.sleep(0.3)

def print_patient_info(patient_id, visit):

    print(f"PATIENT ID: {patient_id}")
    print(f"VISIT: {visit}")
    print(f"Date: 2024-11-06")


def print_modality_features():
    print("MODALITY FEATURES EXTRACTED:")


    print("\n[1] MOTOR FEATURES (14 dimensions):")
    print("    • Speech: 1.2/4.0          • Tremor at rest: 2.3/4.0")
    print("    • Salivation: 0.8/4.0      • Rising from chair: 1.8/4.0")
    print("    • Handwriting: 2.1/4.0     • Walking: 2.5/4.0")
    print("    • Total Motor Score: 32/132")

    print("\n[2] NON-MOTOR FEATURES (205 dimensions across 5 domains):")
    print("    • Cognitive (101): Memory impairment, time management difficulty")
    print("    • Psychological (35): Mild apathy, mood fluctuations")
    print("    • Sleep (13): REM behavior disorder, vivid dreaming")
    print("    • Autonomic (35): Mild orthostatic hypotension")
    print("    • Sensory (21): Hyposmia detected")

    print("\n[3] IMAGING FEATURES (147 dimensions):")
    print("    • MRI (115): Reduced caudate volume, putamen atrophy")
    print("    • DTI (32): White matter integrity loss in substantia nigra")
    print("    • Quality metrics: CNR=1.82, SNR=12.3")

    print("\n"  + "\n")

def print_encoder_outputs():
    print("ENCODER OUTPUTS (Latent Representations):")

    print("  Motor Encoder:     [16-dim] → [0.23, -0.45, 0.67, 0.12, ...]")
    print("  Non-Motor Encoder: [16-dim] → [-0.18, 0.52, -0.31, 0.78, ...]")
    print("  Imaging Encoder:   [16-dim] → [0.44, -0.22, 0.55, -0.09, ...]")
    print("\n  Fused Embedding:   [48-dim] → Ready for classification")
    print( "\n")

def print_attention_weights():
    print("ATTENTION WEIGHTS (Cross-Modal Importance):")

    print("  These weights indicate how much each modality contributes to the final prediction.\n")

    print("  Motor Features:      ████████████░░░░░░░░  0.342 (34.2%)")
    print("  Non-Motor Features:  ███████░░░░░░░░░░░░░  0.238 (23.8%)")
    print("  Imaging Features:    ████████████████░░░░  0.420 (42.0%)")

    print("\n" + "\n")

def print_feature_importance():
    print("TOP 10 DISCRIMINATIVE FEATURES (SHAP Values):")

    print("  Rank  Feature                          Modality    SHAP Value")
    print("  ")
    print("   1.   Putamen Volume                   Imaging     +0.847")
    print("   2.   Handwriting Score (NP2HWRT)      Motor       +0.723")
    print("   3.   Tremor at Rest (NP2TRMR)         Motor       +0.681")
    print("   4.   DTI: Substantia Nigra FA         Imaging     +0.619")
    print("   5.   Walking Difficulty (NP2WALK)     Motor       +0.592")
    print("   6.   Memory Impairment (DIFFREM)      Non-Motor   +0.547")
    print("   7.   REM Behavior Disorder            Non-Motor   +0.501")
    print("   8.   Caudate Volume                   Imaging     +0.478")
    print("   9.   Rising from Chair (NP2RISE)      Motor       +0.446")
    print("  10.   Hyposmia Severity                Non-Motor   +0.412")

    print("\n" + "\n")

def print_stage_predictions():
    print("STAGE PREDICTION PROBABILITIES:")

    print("\n  Early Stage:  ███░░░░░░░░░░░░░░░░░░  0.142 (14.2%)")
    print("  Mid Stage:    ███████████████████░░░  0.783 (78.3%)")
    print("  Late Stage:   ██░░░░░░░░░░░░░░░░░░░  0.075 (7.5%)")

    print("\n  PREDICTED STAGE: MID STAGE (Confidence: 78.3%)")
    print("  ")

    print("\n" + "\n")


def print_model_metadata():
    print("MODEL METADATA:")

    print(f"  Framework Version: 1.0.0")
    print(f"  Training Dataset: PPMI (n=387 patients)")
    print(f"  Cross-Validation Accuracy: 86.3% ± 2.1%")
    print(f"  External Validation Accuracy: 82.9%")
    print(f"  Macro F1-Score: 85.4%")
    print(f"  AUC: 0.873")
    print(f"  Inference Time: 47ms")
    print("\n" + "\n")

def main():
    """Main function to simulate clinical inference output"""

    print_header()
    simulate_loading()

    # Patient 1: Mid-stage prediction
    print("\n" + "█"*80)
    print(" "*30 + "INFERENCE REPORT #1")
    print("█"*80 + "\n")

    print_patient_info("PPMI_4721", "V08 (Month 24)")
    print_modality_features()
    print_encoder_outputs()
    print_attention_weights()
    print_feature_importance()
    print_stage_predictions()


    # Additional patient (Early stage)
    print("\n\n" + "█"*80)
    print(" "*30 + "INFERENCE REPORT #2")
    print("█"*80 + "\n")

    print_patient_info("PPMI_3892", "V04 (Month 12)")


    print("ATTENTION WEIGHTS (Cross-Modal Importance):")

    print("  Motor Features:      ██████████░░░░░░░░░░  0.298 (29.8%)")
    print("  Non-Motor Features:  ██████░░░░░░░░░░░░░░  0.215 (21.5%)")
    print("  Imaging Features:    ████████████████████  0.487 (48.7%)")

    print("\n  PREDICTED STAGE: EARLY STAGE (Confidence: 86.1%)")
    print("  " )

    print("\n" +  "\n")

    # Patient 3: Late stage
    print("\n" + "█"*80)
    print(" "*30 + "INFERENCE REPORT #3")
    print("█"*80 + "\n")

    print_patient_info("PPMI_5103", "V15 (Month 48)")


    print("ATTENTION WEIGHTS (Cross-Modal Importance):")

    print("  Motor Features:      ██████████████████░░  0.461 (46.1%)")
    print("  Non-Motor Features:  ████████████░░░░░░░░  0.312 (31.2%)")
    print("  Imaging Features:    ██████████░░░░░░░░░░  0.227 (22.7%)")

    print("\n  PREDICTED STAGE: LATE STAGE (Confidence: 91.7%)")
    print("  " )

    print("\n" +  "\n")

    print_model_metadata()

    print("\n" + "="*80)
    print("                     INFERENCE COMPLETE")
    print("                All predictions saved to database")
    print( "\n")

if __name__ == "__main__":
    main()

